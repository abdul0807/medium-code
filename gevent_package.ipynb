{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install gevent\n!pip install gipc","execution_count":16,"outputs":[{"output_type":"stream","text":"Requirement already satisfied: gipc in /opt/conda/lib/python3.7/site-packages (1.1.0)\nRequirement already satisfied: gevent<1.5,>=1.2 in /opt/conda/lib/python3.7/site-packages (from gipc) (1.4.0)\nRequirement already satisfied: greenlet>=0.4.14; platform_python_implementation == \"CPython\" in /opt/conda/lib/python3.7/site-packages (from gevent<1.5,>=1.2->gipc) (0.4.15)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Simple Example - using gevent package"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import gevent # loading the gevent package\nfrom time import time # For response time comparisons\nclass Prediction:\n    def __init__(self):\n        pass\n    \n    def first_model_prediction(self, data=None, arg=None):\n        print (\"In first model\")\n        # Code for preprocessing, feature engineering if required\n        # Assuming that this takes ~ 500ms\n        # Let us sleep for 500ms\n        gevent.sleep(0.5)\n        print (\"Out first model\")\n        \n        return \"prediction1\"\n    \n    def second_model_prediction(self, data=None, arg=None):\n        print (\"In second model\")\n        # Code for preprocessing, feature engineering if required\n        # Assuming that this takes ~ 500ms\n        # Let us sleep for 500ms\n        gevent.sleep(0.5)\n        print (\"Out second model\")\n        \n        return \"prediction2\"\n    \n    # final prediction \n    def predict(self, data=None):\n        # Code for preprocessing, feature engineering in case both models uses same features\n        arg = None # Dummy argument\n        \n        # Creating separate threads for each model\n        g1 = gevent.spawn(self.first_model_prediction, data, arg)\n        g2 = gevent.spawn(self.second_model_prediction, data, arg)\n        \n        # Joining the threads together\n        gevent.joinall([g1, g2])\n        \n        # getting the first model results\n        first_model_result = g1.value\n\n        # getting the second model results\n        second_model_result = g2.value\n\n        # Performing some calculations with the results of the two models\n        final_result = first_model_result + second_model_result\n            \n        return final_result","execution_count":17,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Please note that I have used a class instead of simple functions for people interested in Object Oriented Programming. We can instead use simple functions as well."},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = Prediction()\n\ntb = time()\n# Prediction using the first model\nfirst_result = predict.first_model_prediction()\n# Prediction using the second model\nsecond_result = predict.second_model_prediction()\nta = time()\nprint (\"total time taken without using gevent is {}\".format(ta-tb))","execution_count":18,"outputs":[{"output_type":"stream","text":"In first model\nOut first model\nIn second model\nOut second model\ntotal time taken without using gevent is 1.0028834342956543\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"- Since the functions are running sequentially. So calling the functions directly ended up with a response time of close to 1 second. \n- As seen, The sequence of output is first model In and Out. Then second model In and Out.\n\n- Let us try using the predict function which uses gevent and run the models in parallel."},{"metadata":{"trusted":true},"cell_type":"code","source":"tb = time()\nresult = predict.predict(None)\nta = time()\nprint (\"total time taken using gevent is {}\".format(ta-tb))","execution_count":19,"outputs":[{"output_type":"stream","text":"In first model\nIn second model\nOut first model\nOut second model\ntotal time taken using gevent is 0.5018832683563232\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"- As shown above, the model prediction ran in parallel. First model and Second model In together and are processed simultaneously. And the response time is now close to 500ms.\n\n- The total time taken is the maximum of the time taken by both the function."},{"metadata":{},"cell_type":"markdown","source":"## Simple Example - using Gipc Package\n\n- Let us try the same previous example using gipc package"},{"metadata":{"trusted":true},"cell_type":"code","source":"import gipc # loading the gipc package\n\nclass GipcPrediction:\n    def __init__(self):\n        pass\n    \n    def first_model_prediction(self, data=None, arg=None):\n        print (\"In first model\")\n        # Code for preprocessing, feature engineering if required\n        # Assuming that this takes ~ 500ms\n        # Let us sleep for 500ms\n        gevent.sleep(0.5)\n        \n        print (\"Out first model\")\n        \n        return \"prediction1\"\n    \n    def second_model_prediction(self, writer=None, data=None, arg=None):\n        # Code for preprocessing, feature engineering if required\n        # Assuming that this takes ~ 500ms\n        # Let us sleep for 500ms\n        gevent.sleep(0.5)\n\n        # Check if the writer exist and put the response in the writer\n        if writer is not None:\n            writer.put(result)\n\n        # The below return statement never execute when running this function as child process\n        # The return is used to ensure that this function can be directly used as well, without parallel processing.\n        return \"prediction2\"\n\n    def predict(self, data=None):\n        # Code for preprocessing, feature engineering in case both models uses same features\n        arg = None # Dummy argument\n\n        # Creating a gipc pipeline\n        # `reader` is the channel end for the parent, `writer` for the child.\n        with gipc.pipe() as (reader, writer):\n            g = gevent.spawn(self.first_model_prediction, data, arg)\n            p = gipc.start_process(target=self.second_model_prediction, args=(writer, data, arg))\n\n            # Joining the process together\n            g.join()\n            p.join()\n\n            # getting the first model results\n            first_model_result = g.value\n\n            # getting the second model results\n            second_model_result = reader.get()\n\n            # Performing some calculations with the results of the two models\n            final_result = first_model_result + second_model_result\n\n        return final_result","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gipc_obj = GipcPrediction()\n\ntb = time()\n# Prediction using the first model\nfirst_result = predict.first_model_prediction()\n# Prediction using the second model\nsecond_result = predict.second_model_prediction()\nta = time()\nprint (\"total time taken without using gevent is {}\".format(ta-tb))","execution_count":21,"outputs":[{"output_type":"stream","text":"In first model\nOut first model\nIn second model\nOut second model\ntotal time taken without using gevent is 1.00284743309021\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tb = time()\nresult = gipc_obj.predict(None)\nta = time()\nprint (\"total time taken using gevent is {}\".format(ta-tb))","execution_count":22,"outputs":[{"output_type":"stream","text":"In first model\nOut first model\ntotal time taken using gevent is 0.5208356380462646\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"- As shown above, the model prediction ran in parallel. And the response time is now close to 500ms."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}